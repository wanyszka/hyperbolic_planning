{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# MDP Hyperbolic Embeddings: Hitting Time Conjecture\n\nThis notebook explores hyperbolic embeddings for (state, goal) pairs in a 6-state MDP.\n\n**Conjecture:**\n- **Norm** (distance from origin) correlates **negatively** with **variance** in hitting times (low variance → high norm, high variance → low norm)\n- **Angular coordinate** correlates with **mean** hitting times\n\n## MDP Structure\n```\nState 1 (start)\n    |\n    |-- a11 (stochastic) --> 4 (p=0.5) or 5 (p=0.5) --> 6 (goal)\n    |\n    |-- a12 (deterministic) --> 2 --> (0.9 self-loop, 0.1 to 4) --> 6\n    |\n    |-- a13 (deterministic) --> 3 --> (0.9 self-loop, 0.1 to 5) --> 6\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hypll geoopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Import hypll library\n",
    "from hypll.manifolds.poincare_ball import PoincareBall, Curvature\n",
    "from hypll.tensors.manifold_tensor import ManifoldTensor\n",
    "from hypll.tensors import TangentTensor\n",
    "import hypll.nn as hnn\n",
    "\n",
    "# Setup\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDP Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMDP:\n",
    "    \"\"\"\n",
    "    6-state MDP with the following structure:\n",
    "    \n",
    "    States (0-indexed internally, displayed as 1-6):\n",
    "        0 (State 1): Start state, 3 actions available\n",
    "        1 (State 2): Self-loop (0.9) or to state 3 (0.1)\n",
    "        2 (State 3): Self-loop (0.9) or to state 4 (0.1)\n",
    "        3 (State 4): Deterministic to goal (state 5)\n",
    "        4 (State 5): Deterministic to goal (state 5)\n",
    "        5 (State 6): Goal (terminal)\n",
    "    \n",
    "    From state 0:\n",
    "        - a0: Stochastic -> state 3 (p=0.5) or state 4 (p=0.5)\n",
    "        - a1: Deterministic -> state 1\n",
    "        - a2: Deterministic -> state 2\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.n_states = 6\n",
    "        self.start_state = 0  # State 1\n",
    "        self.goal_state = 5   # State 6\n",
    "        \n",
    "        # Number of actions per state\n",
    "        self.n_actions = {\n",
    "            0: 3,  # State 1: a11, a12, a13\n",
    "            1: 1,  # State 2: only one action (stochastic outcome)\n",
    "            2: 1,  # State 3: only one action (stochastic outcome)\n",
    "            3: 1,  # State 4: deterministic to goal\n",
    "            4: 1,  # State 5: deterministic to goal\n",
    "            5: 0,  # State 6: terminal\n",
    "        }\n",
    "        \n",
    "    def get_transitions(self, state, action):\n",
    "        \"\"\"\n",
    "        Get transition probabilities for (state, action) pair.\n",
    "        Returns list of (next_state, probability) tuples.\n",
    "        \"\"\"\n",
    "        if state == 0:  # State 1 (start)\n",
    "            if action == 0:  # a11: stochastic\n",
    "                return [(3, 0.5), (4, 0.5)]  # -> State 4 or 5\n",
    "            elif action == 1:  # a12: deterministic\n",
    "                return [(1, 1.0)]  # -> State 2\n",
    "            elif action == 2:  # a13: deterministic\n",
    "                return [(2, 1.0)]  # -> State 3\n",
    "        \n",
    "        elif state == 1:  # State 2\n",
    "            return [(1, 0.9), (3, 0.1)]  # Self-loop or -> State 4\n",
    "        \n",
    "        elif state == 2:  # State 3\n",
    "            return [(2, 0.9), (4, 0.1)]  # Self-loop or -> State 5\n",
    "        \n",
    "        elif state == 3:  # State 4\n",
    "            return [(5, 1.0)]  # -> Goal (State 6)\n",
    "        \n",
    "        elif state == 4:  # State 5\n",
    "            return [(5, 1.0)]  # -> Goal (State 6)\n",
    "        \n",
    "        elif state == 5:  # State 6 (goal)\n",
    "            return [(5, 1.0)]  # Stay at goal\n",
    "        \n",
    "        return []\n",
    "    \n",
    "    def step(self, state, action=None):\n",
    "        \"\"\"\n",
    "        Take a step from state with given action.\n",
    "        If action is None, sample uniformly from available actions.\n",
    "        Returns next_state.\n",
    "        \"\"\"\n",
    "        if state == self.goal_state:\n",
    "            return state\n",
    "        \n",
    "        if action is None:\n",
    "            n_actions = self.n_actions[state]\n",
    "            action = np.random.randint(0, max(1, n_actions))\n",
    "        \n",
    "        transitions = self.get_transitions(state, action)\n",
    "        \n",
    "        if len(transitions) == 1:\n",
    "            return transitions[0][0]\n",
    "        \n",
    "        # Sample according to probabilities\n",
    "        probs = [t[1] for t in transitions]\n",
    "        next_states = [t[0] for t in transitions]\n",
    "        return np.random.choice(next_states, p=probs)\n",
    "    \n",
    "    def state_name(self, state):\n",
    "        \"\"\"Return human-readable state name.\"\"\"\n",
    "        return f\"S{state + 1}\"\n",
    "\n",
    "\n",
    "# Test the MDP\n",
    "mdp = SimpleMDP()\n",
    "print(\"MDP Structure Test:\")\n",
    "print(f\"Start state: {mdp.state_name(mdp.start_state)}\")\n",
    "print(f\"Goal state: {mdp.state_name(mdp.goal_state)}\")\n",
    "print()\n",
    "for state in range(mdp.n_states):\n",
    "    print(f\"{mdp.state_name(state)}: {mdp.n_actions[state]} actions\")\n",
    "    for action in range(mdp.n_actions[state]):\n",
    "        transitions = mdp.get_transitions(state, action)\n",
    "        trans_str = \", \".join([f\"{mdp.state_name(s)} (p={p})\" for s, p in transitions])\n",
    "        print(f\"  a{action}: {trans_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "def visualize_mdp_graph(mdp):\n    \"\"\"\n    Visualize the MDP as a directed graph.\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(14, 8))\n    \n    # Node positions (manually designed for clarity)\n    positions = {\n        0: (0, 0),      # S1 (start)\n        1: (-2, -1.5),  # S2\n        2: (2, -1.5),   # S3\n        3: (-1, -3),    # S4\n        4: (1, -3),     # S5\n        5: (0, -4.5),   # S6 (goal)\n    }\n    \n    # Draw nodes\n    node_colors = {\n        0: '#90EE90',  # Start - light green\n        5: '#FFD700',  # Goal - gold\n    }\n    default_color = '#87CEEB'  # Light blue\n    \n    for state, pos in positions.items():\n        color = node_colors.get(state, default_color)\n        circle = plt.Circle(pos, 0.35, color=color, ec='black', linewidth=2, zorder=5)\n        ax.add_patch(circle)\n        \n        # Label\n        label = mdp.state_name(state)\n        if state == 0:\n            label += \"\\n(start)\"\n        elif state == 5:\n            label += \"\\n(goal)\"\n        ax.text(pos[0], pos[1], label, ha='center', va='center', fontsize=11, fontweight='bold', zorder=6)\n    \n    # Draw edges with arrows\n    def draw_arrow(start, end, label=\"\", color='black', style='-', offset=0, curve=0):\n        x1, y1 = positions[start]\n        x2, y2 = positions[end]\n        \n        # Calculate direction\n        dx, dy = x2 - x1, y2 - y1\n        dist = np.sqrt(dx**2 + dy**2)\n        \n        # Shorten to not overlap with circles\n        r = 0.4\n        x1 += r * dx / dist\n        y1 += r * dy / dist\n        x2 -= r * dx / dist\n        y2 -= r * dy / dist\n        \n        # Apply offset for parallel edges\n        if offset != 0:\n            perp_x, perp_y = -dy / dist, dx / dist\n            x1 += offset * perp_x\n            y1 += offset * perp_y\n            x2 += offset * perp_x\n            y2 += offset * perp_y\n        \n        if curve == 0:\n            ax.annotate(\"\", xy=(x2, y2), xytext=(x1, y1),\n                       arrowprops=dict(arrowstyle='->', color=color, lw=2, ls=style))\n        else:\n            ax.annotate(\"\", xy=(x2, y2), xytext=(x1, y1),\n                       arrowprops=dict(arrowstyle='->', color=color, lw=2, ls=style,\n                                      connectionstyle=f\"arc3,rad={curve}\"))\n        \n        if label:\n            mid_x, mid_y = (x1 + x2) / 2 + offset * 0.3, (y1 + y2) / 2\n            ax.text(mid_x, mid_y, label, fontsize=9, ha='center', va='bottom',\n                   bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8))\n    \n    # Draw self-loops\n    def draw_self_loop(state, label=\"\", direction='left'):\n        x, y = positions[state]\n        if direction == 'left':\n            loop_x, loop_y = x - 0.6, y\n            theta1, theta2 = 120, 240\n        else:\n            loop_x, loop_y = x + 0.6, y\n            theta1, theta2 = -60, 60\n        \n        from matplotlib.patches import FancyArrowPatch, Arc\n        arc = Arc((loop_x, loop_y), 0.5, 0.5, angle=0, theta1=theta1, theta2=theta2, \n                  color='black', lw=2)\n        ax.add_patch(arc)\n        \n        # Arrow head\n        if direction == 'left':\n            ax.annotate(\"\", xy=(x-0.35, y+0.15), xytext=(x-0.4, y+0.25),\n                       arrowprops=dict(arrowstyle='->', color='black', lw=2))\n        \n        ax.text(loop_x - 0.3, loop_y, label, fontsize=9, ha='right', va='center',\n               bbox=dict(boxstyle='round,pad=0.2', facecolor='lightyellow', alpha=0.9))\n    \n    # Edges from S1\n    draw_arrow(0, 3, \"a₁₁: p=0.5\", color='blue', offset=-0.15, curve=-0.2)\n    draw_arrow(0, 4, \"a₁₁: p=0.5\", color='blue', offset=0.15, curve=0.2)\n    draw_arrow(0, 1, \"a₁₂\", color='green')\n    draw_arrow(0, 2, \"a₁₃\", color='green')\n    \n    # Self-loops and exits for S2, S3\n    draw_self_loop(1, \"0.9\", direction='left')\n    draw_arrow(1, 3, \"0.1\", color='red')\n    \n    draw_self_loop(2, \"0.9\", direction='right')\n    draw_arrow(2, 4, \"0.1\", color='red')\n    \n    # Deterministic to goal\n    draw_arrow(3, 5, \"1.0\", color='purple')\n    draw_arrow(4, 5, \"1.0\", color='purple')\n    \n    # Legend\n    legend_elements = [\n        plt.Line2D([0], [0], color='blue', lw=2, label='a₁₁: Stochastic'),\n        plt.Line2D([0], [0], color='green', lw=2, label='a₁₂, a₁₃: Deterministic'),\n        plt.Line2D([0], [0], color='red', lw=2, label='Stochastic exit'),\n        plt.Line2D([0], [0], color='purple', lw=2, label='To goal'),\n    ]\n    ax.legend(handles=legend_elements, loc='upper right', fontsize=10)\n    \n    ax.set_xlim(-4, 4)\n    ax.set_ylim(-5.5, 1)\n    ax.set_aspect('equal')\n    ax.axis('off')\n    ax.set_title('MDP Structure', fontsize=16, fontweight='bold', pad=20)\n    \n    plt.tight_layout()\n    plt.savefig('mdp_graph.png', dpi=150, bbox_inches='tight', facecolor='white')\n    plt.show()\n\n\n# Visualize the MDP\nvisualize_mdp_graph(mdp)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mdp_trajectories(mdp, n_trajectories, max_length=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Generate trajectories from start to goal under uniform random policy.\n",
    "    \n",
    "    Args:\n",
    "        mdp: SimpleMDP instance\n",
    "        n_trajectories: Number of trajectories to generate\n",
    "        max_length: Maximum trajectory length\n",
    "        seed: Random seed\n",
    "    \n",
    "    Returns:\n",
    "        List of state sequences (lists of state indices)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    trajectories = []\n",
    "    \n",
    "    for _ in range(n_trajectories):\n",
    "        traj = [mdp.start_state]\n",
    "        state = mdp.start_state\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            if state == mdp.goal_state:\n",
    "                break\n",
    "            \n",
    "            # Uniform random action selection\n",
    "            state = mdp.step(state, action=None)\n",
    "            traj.append(state)\n",
    "        \n",
    "        trajectories.append(traj)\n",
    "    \n",
    "    return trajectories\n",
    "\n",
    "\n",
    "# Generate trajectories\n",
    "trajectories = generate_mdp_trajectories(mdp, n_trajectories=5000, max_length=1000, seed=42)\n",
    "\n",
    "# Analyze trajectories\n",
    "lengths = [len(t) for t in trajectories]\n",
    "print(f\"Generated {len(trajectories)} trajectories\")\n",
    "print(f\"Length stats: mean={np.mean(lengths):.1f}, std={np.std(lengths):.1f}, min={min(lengths)}, max={max(lengths)}\")\n",
    "\n",
    "# Show sample trajectories\n",
    "print(\"\\nSample trajectories:\")\n",
    "for i in range(5):\n",
    "    traj_str = \" -> \".join([mdp.state_name(s) for s in trajectories[i][:15]])\n",
    "    if len(trajectories[i]) > 15:\n",
    "        traj_str += f\" ... ({len(trajectories[i])} states total)\"\n",
    "    print(f\"  {i+1}: {traj_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDPContrastiveDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for contrastive learning on MDP trajectory intervals.\n",
    "    \n",
    "    For each sample:\n",
    "    - Anchor: [start_state, goal_state] interval from trajectory\n",
    "    - Positive: Subinterval [k, l] where anchor_i <= k <= l <= anchor_j\n",
    "    - Negatives: Intervals that are NOT subintervals of anchor\n",
    "    \n",
    "    States are normalized to [0, 1] by dividing by (n_states - 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, trajectories, n_states=6, num_samples=10000, n_negatives=5, seed=42):\n",
    "        self.trajectories = trajectories\n",
    "        self.n_states = n_states\n",
    "        self.num_samples = num_samples\n",
    "        self.n_negatives = n_negatives\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        # Filter valid trajectories (need at least 2 states for intervals)\n",
    "        self.valid_traj_indices = [i for i, t in enumerate(trajectories) if len(t) >= 2]\n",
    "        \n",
    "        # Pre-generate all samples\n",
    "        self.anchors, self.positives, self.negatives = self._generate_all_samples()\n",
    "    \n",
    "    def _normalize_state(self, state):\n",
    "        \"\"\"Normalize state index to [0, 1].\"\"\"\n",
    "        return state / (self.n_states - 1)\n",
    "    \n",
    "    def _generate_all_samples(self):\n",
    "        anchors = []\n",
    "        positives = []\n",
    "        negatives_list = []\n",
    "        \n",
    "        for _ in range(self.num_samples):\n",
    "            anchor, positive, negs = self._generate_single_sample()\n",
    "            anchors.append(anchor)\n",
    "            positives.append(positive)\n",
    "            negatives_list.append(negs)\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(anchors, dtype=torch.float32),\n",
    "            torch.tensor(positives, dtype=torch.float32),\n",
    "            torch.tensor(negatives_list, dtype=torch.float32),\n",
    "        )\n",
    "    \n",
    "    def _generate_single_sample(self):\n",
    "        \"\"\"Generate a single (anchor, positive, negatives) tuple.\"\"\"\n",
    "        # Sample trajectory\n",
    "        traj_idx = np.random.choice(self.valid_traj_indices)\n",
    "        traj = self.trajectories[traj_idx]\n",
    "        T = len(traj) - 1\n",
    "        \n",
    "        # Sample anchor interval [i, j] where i <= j\n",
    "        j = np.random.randint(0, T + 1)\n",
    "        i = np.random.randint(0, j + 1)\n",
    "        \n",
    "        anchor = [self._normalize_state(traj[i]), self._normalize_state(traj[j])]\n",
    "        \n",
    "        # Sample positive (subinterval): i <= k <= l <= j\n",
    "        l = np.random.randint(i, j + 1)\n",
    "        k = np.random.randint(i, l + 1)\n",
    "        \n",
    "        positive = [self._normalize_state(traj[k]), self._normalize_state(traj[l])]\n",
    "        \n",
    "        # Sample negatives (non-subintervals)\n",
    "        negatives = []\n",
    "        for _ in range(self.n_negatives):\n",
    "            neg = self._sample_negative(traj, i, j, T)\n",
    "            negatives.append(neg)\n",
    "        \n",
    "        return anchor, positive, negatives\n",
    "    \n",
    "    def _sample_negative(self, traj, anchor_i, anchor_j, T, max_attempts=1000):\n",
    "        \"\"\"Sample an interval that is NOT a subinterval of anchor.\"\"\"\n",
    "        for _ in range(max_attempts):\n",
    "            l = np.random.randint(0, T + 1)\n",
    "            k = np.random.randint(0, l + 1)\n",
    "            \n",
    "            # Check if NOT a subinterval (temporal containment)\n",
    "            is_subinterval = (anchor_i <= k) and (l <= anchor_j)\n",
    "            \n",
    "            if not is_subinterval:\n",
    "                return [self._normalize_state(traj[k]), self._normalize_state(traj[l])]\n",
    "        \n",
    "        # Fallback\n",
    "        if anchor_i > 0:\n",
    "            return [self._normalize_state(traj[0]), self._normalize_state(traj[0])]\n",
    "        else:\n",
    "            return [self._normalize_state(traj[T]), self._normalize_state(traj[T])]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.anchors[idx], self.positives[idx], self.negatives[idx]\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "dataset = MDPContrastiveDataset(\n",
    "    trajectories=trajectories,\n",
    "    n_states=6,\n",
    "    num_samples=10000,\n",
    "    n_negatives=5,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Check shapes\n",
    "anchor, positive, negatives = dataset[0]\n",
    "print(f\"Anchor shape: {anchor.shape}\")\n",
    "print(f\"Positive shape: {positive.shape}\")\n",
    "print(f\"Negatives shape: {negatives.shape}\")\n",
    "print(f\"\\nSample anchor: {anchor}\")\n",
    "print(f\"Sample positive: {positive}\")\n",
    "print(f\"Sample negatives[0]: {negatives[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperbolic Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manifold_map(x, manifold):\n",
    "    \"\"\"Map Euclidean tensor to hyperbolic manifold via exponential map.\"\"\"\n",
    "    tangents = TangentTensor(x, man_dim=-1, manifold=manifold)\n",
    "    return manifold.expmap(tangents)\n",
    "\n",
    "\n",
    "class HyperbolicIntervalEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encode (state, goal) pairs to Poincare ball.\n",
    "    Architecture: 2 Euclidean layers + 2 Hyperbolic layers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim=2, c=1.0, euc_width=128, hyp_width=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create manifold\n",
    "        curvature = Curvature(value=c, requires_grad=False)\n",
    "        self.manifold = PoincareBall(c=curvature)\n",
    "        \n",
    "        # Euclidean layers\n",
    "        self.euc_layer1 = nn.Linear(2, euc_width)\n",
    "        self.euc_layer2 = nn.Linear(euc_width, hyp_width)\n",
    "        self.euc_relu = nn.ReLU()\n",
    "        \n",
    "        # Hyperbolic layers\n",
    "        self.hyp_layer1 = hnn.HLinear(\n",
    "            in_features=hyp_width,\n",
    "            out_features=hyp_width,\n",
    "            manifold=self.manifold\n",
    "        )\n",
    "        self.hyp_layer2 = hnn.HLinear(\n",
    "            in_features=hyp_width,\n",
    "            out_features=embedding_dim,\n",
    "            manifold=self.manifold\n",
    "        )\n",
    "        self.hyp_relu = hnn.HReLU(manifold=self.manifold)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Euclidean part\n",
    "        x = self.euc_relu(self.euc_layer1(x))\n",
    "        x = self.euc_layer2(x)\n",
    "        \n",
    "        # Map to hyperbolic space\n",
    "        x = manifold_map(x, self.manifold)\n",
    "        \n",
    "        # Hyperbolic part\n",
    "        x = self.hyp_relu(self.hyp_layer1(x))\n",
    "        x = self.hyp_layer2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# Test encoder\n",
    "model = HyperbolicIntervalEncoder(embedding_dim=2, c=1.0).to(device)\n",
    "test_input = torch.tensor([[0.0, 1.0], [0.2, 0.8]], dtype=torch.float32).to(device)\n",
    "test_output = model(test_input)\n",
    "print(f\"Test input shape: {test_input.shape}\")\n",
    "print(f\"Test output type: {type(test_output)}\")\n",
    "if isinstance(test_output, ManifoldTensor):\n",
    "    print(f\"Test output tensor shape: {test_output.tensor.shape}\")\n",
    "    print(f\"Test output: {test_output.tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_nce_loss(anchor, positive, negatives, manifold, temperature=0.5):\n",
    "    \"\"\"InfoNCE loss using hyperbolic distance.\"\"\"\n",
    "    batch_size = anchor.shape[0] if not isinstance(anchor, ManifoldTensor) else anchor.tensor.shape[0]\n",
    "    num_neg = negatives.shape[1] if not isinstance(negatives, ManifoldTensor) else negatives.tensor.shape[1]\n",
    "    \n",
    "    # Compute positive distance\n",
    "    pos_dist = manifold.dist(x=anchor, y=positive)\n",
    "    \n",
    "    # Expand anchor for negative comparisons\n",
    "    if isinstance(anchor, ManifoldTensor):\n",
    "        anchor_tensor = anchor.tensor.unsqueeze(1).expand(-1, num_neg, -1)\n",
    "        anchor_expanded = ManifoldTensor(anchor_tensor, manifold=manifold)\n",
    "    else:\n",
    "        anchor_expanded = anchor.unsqueeze(1).expand(-1, num_neg, -1)\n",
    "    \n",
    "    neg_dist = manifold.dist(x=anchor_expanded, y=negatives)\n",
    "    \n",
    "    # Extract tensors\n",
    "    if isinstance(pos_dist, ManifoldTensor):\n",
    "        pos_dist = pos_dist.tensor\n",
    "    if isinstance(neg_dist, ManifoldTensor):\n",
    "        neg_dist = neg_dist.tensor\n",
    "    \n",
    "    # Reshape\n",
    "    if pos_dist.dim() > 1:\n",
    "        pos_dist = pos_dist.squeeze(-1)\n",
    "    if neg_dist.dim() > 2:\n",
    "        neg_dist = neg_dist.squeeze(-1)\n",
    "    \n",
    "    # Check for NaN\n",
    "    if torch.isnan(pos_dist).any() or torch.isnan(neg_dist).any():\n",
    "        print(\"WARNING: NaN in distances\")\n",
    "        return torch.tensor(0.0, device=pos_dist.device, requires_grad=True)\n",
    "    \n",
    "    # Convert distances to similarities\n",
    "    pos_sim = -pos_dist / temperature\n",
    "    neg_sim = -neg_dist / temperature\n",
    "    \n",
    "    # Combine for cross-entropy\n",
    "    logits = torch.cat([pos_sim.unsqueeze(1), neg_sim], dim=1)\n",
    "    labels = torch.zeros(batch_size, dtype=torch.long, device=logits.device)\n",
    "    \n",
    "    loss = nn.functional.cross_entropy(logits, labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, num_epochs=200, batch_size=32, lr=0.001, temperature=0.1):\n",
    "    \"\"\"Train the hyperbolic encoder.\"\"\"\n",
    "    from hypll.optim import RiemannianAdam\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    optimizer = RiemannianAdam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-5)\n",
    "    \n",
    "    losses = []\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for anchor, positive, negatives in dataloader:\n",
    "            anchor = anchor.to(device)\n",
    "            positive = positive.to(device)\n",
    "            negatives = negatives.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            anchor_emb = model(anchor)\n",
    "            positive_emb = model(positive)\n",
    "            \n",
    "            bs, num_neg, _ = negatives.shape\n",
    "            negatives_emb = model(negatives.view(-1, 2))\n",
    "            \n",
    "            # Reshape negatives\n",
    "            if isinstance(negatives_emb, ManifoldTensor):\n",
    "                neg_tensor = negatives_emb.tensor.view(bs, num_neg, -1)\n",
    "                negatives_emb = ManifoldTensor(neg_tensor, manifold=model.manifold)\n",
    "            else:\n",
    "                negatives_emb = negatives_emb.view(bs, num_neg, -1)\n",
    "            \n",
    "            # Loss\n",
    "            loss = info_nce_loss(anchor_emb, positive_emb, negatives_emb,\n",
    "                                model.manifold, temperature=temperature)\n",
    "            \n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(f\"Skipping batch due to NaN/Inf loss\")\n",
    "                continue\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        if num_batches > 0:\n",
    "            avg_loss = epoch_loss / num_batches\n",
    "            losses.append(avg_loss)\n",
    "            scheduler.step()\n",
    "            \n",
    "            if (epoch + 1) % 20 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = HyperbolicIntervalEncoder(embedding_dim=2, c=1.0, euc_width=128, hyp_width=128).to(device)\n",
    "losses = train_model(model, dataset, num_epochs=200, batch_size=32, lr=0.001, temperature=0.1)\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hitting Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hitting_times(mdp, start_state, goal_state=5, n_simulations=10000, max_steps=10000):\n",
    "    \"\"\"\n",
    "    Monte Carlo estimation of hitting times from start_state to goal_state\n",
    "    under uniform random policy.\n",
    "    \n",
    "    Returns (mean, variance, std) of hitting times.\n",
    "    \"\"\"\n",
    "    hitting_times = []\n",
    "    \n",
    "    for _ in range(n_simulations):\n",
    "        state = start_state\n",
    "        steps = 0\n",
    "        \n",
    "        while state != goal_state and steps < max_steps:\n",
    "            state = mdp.step(state, action=None)\n",
    "            steps += 1\n",
    "        \n",
    "        if state == goal_state:\n",
    "            hitting_times.append(steps)\n",
    "    \n",
    "    if len(hitting_times) == 0:\n",
    "        return float('inf'), float('inf'), float('inf')\n",
    "    \n",
    "    return np.mean(hitting_times), np.var(hitting_times), np.std(hitting_times)\n",
    "\n",
    "\n",
    "def compute_all_hitting_times(mdp, n_simulations=10000):\n",
    "    \"\"\"\n",
    "    Compute hitting time statistics for all (start, goal) pairs.\n",
    "    \n",
    "    Returns dict: {start_state: {'mean': ..., 'var': ..., 'std': ...}}\n",
    "    \"\"\"\n",
    "    hitting_stats = {}\n",
    "    goal = mdp.goal_state\n",
    "    \n",
    "    for start in range(mdp.n_states):\n",
    "        if start != goal:\n",
    "            mean, var, std = compute_hitting_times(mdp, start, goal, n_simulations)\n",
    "            hitting_stats[start] = {'mean': mean, 'var': var, 'std': std}\n",
    "            print(f\"{mdp.state_name(start)} -> {mdp.state_name(goal)}: mean={mean:.2f}, var={var:.2f}, std={std:.2f}\")\n",
    "    \n",
    "    return hitting_stats\n",
    "\n",
    "\n",
    "# Compute hitting times\n",
    "print(\"Computing hitting time statistics...\")\n",
    "print(\"=\"*60)\n",
    "hitting_stats = compute_all_hitting_times(mdp, n_simulations=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization on Poincare Ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def plot_mdp_embeddings(embeddings, hitting_stats, mdp):\n    \"\"\"\n    Visualize embeddings on the Poincare disk, colored by hitting time statistics.\n    \"\"\"\n    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n    \n    states = sorted(embeddings.keys())\n    coords = np.array([embeddings[s] for s in states])\n    means = np.array([hitting_stats[s]['mean'] for s in states])\n    vars_ = np.array([hitting_stats[s]['var'] for s in states])\n    \n    # Plot 1: Colored by mean hitting time\n    ax = axes[0]\n    plot_poincare_disk(ax, \"Colored by Mean Hitting Time\")\n    scatter = ax.scatter(coords[:, 0], coords[:, 1], c=means, cmap='viridis',\n                        s=120, edgecolors='black', linewidth=1.5, zorder=5)\n    plt.colorbar(scatter, ax=ax, label='Mean Hitting Time')\n    \n    for s in states:\n        emb = embeddings[s]\n        ax.annotate(mdp.state_name(s), (emb[0], emb[1]), fontsize=12, fontweight='bold',\n                   xytext=(6, 6), textcoords='offset points')\n    \n    # Plot 2: Colored by variance\n    ax = axes[1]\n    plot_poincare_disk(ax, \"Colored by Variance of Hitting Time\")\n    scatter = ax.scatter(coords[:, 0], coords[:, 1], c=vars_, cmap='plasma',\n                        s=120, edgecolors='black', linewidth=1.5, zorder=5)\n    plt.colorbar(scatter, ax=ax, label='Variance')\n    \n    for s in states:\n        emb = embeddings[s]\n        ax.annotate(mdp.state_name(s), (emb[0], emb[1]), fontsize=12, fontweight='bold',\n                   xytext=(6, 6), textcoords='offset points')\n    \n    # Plot 3: Labeled with all info\n    ax = axes[2]\n    plot_poincare_disk(ax, \"All State Embeddings\")\n    \n    colors = plt.cm.tab10(np.linspace(0, 1, len(states)))\n    for i, s in enumerate(states):\n        emb = embeddings[s]\n        ax.scatter([emb[0]], [emb[1]], c=[colors[i]], s=120,\n                  edgecolors='black', linewidth=1.5, zorder=5,\n                  label=f\"{mdp.state_name(s)}: T={hitting_stats[s]['mean']:.1f}\")\n        ax.annotate(mdp.state_name(s), (emb[0], emb[1]), fontsize=12, fontweight='bold',\n                   xytext=(6, 6), textcoords='offset points')\n    \n    ax.legend(loc='upper right', fontsize=10)\n    \n    plt.tight_layout()\n    plt.savefig('mdp_embeddings.png', dpi=150, bbox_inches='tight')\n    plt.show()\n\n\nplot_mdp_embeddings(embeddings, hitting_stats, mdp)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mdp_embeddings(embeddings, hitting_stats, mdp):\n",
    "    \"\"\"\n",
    "    Visualize embeddings on the Poincare disk, colored by hitting time statistics.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    states = sorted(embeddings.keys())\n",
    "    coords = np.array([embeddings[s] for s in states])\n",
    "    means = np.array([hitting_stats[s]['mean'] for s in states])\n",
    "    vars_ = np.array([hitting_stats[s]['var'] for s in states])\n",
    "    \n",
    "    # Plot 1: Colored by mean hitting time\n",
    "    ax = axes[0]\n",
    "    plot_poincare_disk(ax, \"Colored by Mean Hitting Time\")\n",
    "    scatter = ax.scatter(coords[:, 0], coords[:, 1], c=means, cmap='viridis',\n",
    "                        s=300, edgecolors='black', linewidth=2, zorder=5)\n",
    "    plt.colorbar(scatter, ax=ax, label='Mean Hitting Time')\n",
    "    \n",
    "    for s in states:\n",
    "        emb = embeddings[s]\n",
    "        ax.annotate(mdp.state_name(s), (emb[0], emb[1]), fontsize=14, fontweight='bold',\n",
    "                   xytext=(8, 8), textcoords='offset points')\n",
    "    \n",
    "    # Plot 2: Colored by variance\n",
    "    ax = axes[1]\n",
    "    plot_poincare_disk(ax, \"Colored by Variance of Hitting Time\")\n",
    "    scatter = ax.scatter(coords[:, 0], coords[:, 1], c=vars_, cmap='plasma',\n",
    "                        s=300, edgecolors='black', linewidth=2, zorder=5)\n",
    "    plt.colorbar(scatter, ax=ax, label='Variance')\n",
    "    \n",
    "    for s in states:\n",
    "        emb = embeddings[s]\n",
    "        ax.annotate(mdp.state_name(s), (emb[0], emb[1]), fontsize=14, fontweight='bold',\n",
    "                   xytext=(8, 8), textcoords='offset points')\n",
    "    \n",
    "    # Plot 3: Labeled with all info\n",
    "    ax = axes[2]\n",
    "    plot_poincare_disk(ax, \"All State Embeddings\")\n",
    "    \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(states)))\n",
    "    for i, s in enumerate(states):\n",
    "        emb = embeddings[s]\n",
    "        ax.scatter([emb[0]], [emb[1]], c=[colors[i]], s=300,\n",
    "                  edgecolors='black', linewidth=2, zorder=5,\n",
    "                  label=f\"{mdp.state_name(s)}: T={hitting_stats[s]['mean']:.1f}\")\n",
    "        ax.annotate(mdp.state_name(s), (emb[0], emb[1]), fontsize=14, fontweight='bold',\n",
    "                   xytext=(8, 8), textcoords='offset points')\n",
    "    \n",
    "    ax.legend(loc='upper right', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('mdp_embeddings.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_mdp_embeddings(embeddings, hitting_stats, mdp)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def test_conjecture(embeddings, hitting_stats, mdp):\n    \"\"\"\n    Test the conjecture:\n    - Norm (distance from origin) correlates NEGATIVELY with variance in hitting times\n      (low variance -> high norm, high variance -> low norm)\n    - Angular coordinate correlates with mean hitting times\n    \"\"\"\n    states = sorted(embeddings.keys())\n    \n    # Extract data\n    coords = np.array([embeddings[s] for s in states])\n    norms = np.array([hyperbolic_norm(embeddings[s]) for s in states])\n    angles = np.array([np.arctan2(embeddings[s][1], embeddings[s][0]) for s in states])\n    \n    means = np.array([hitting_stats[s]['mean'] for s in states])\n    vars_ = np.array([hitting_stats[s]['var'] for s in states])\n    stds = np.array([hitting_stats[s]['std'] for s in states])\n    \n    # Compute correlations\n    corr_norm_var, p_norm_var = stats.spearmanr(norms, vars_)\n    corr_norm_std, p_norm_std = stats.spearmanr(norms, stds)\n    corr_angle_mean, p_angle_mean = stats.spearmanr(angles, means)\n    \n    # Also compute Pearson\n    pearson_norm_var = np.corrcoef(norms, vars_)[0, 1]\n    pearson_angle_mean = np.corrcoef(angles, means)[0, 1]\n    \n    print(\"=\"*70)\n    print(\"CONJECTURE TEST RESULTS\")\n    print(\"=\"*70)\n    \n    print(\"\\n1. NORM vs VARIANCE Conjecture:\")\n    print(f\"   Spearman correlation: {corr_norm_var:.4f} (p={p_norm_var:.4f})\")\n    print(f\"   Pearson correlation:  {pearson_norm_var:.4f}\")\n    print(f\"   Expected: NEGATIVE (low variance -> high norm)\")\n    norm_var_supported = corr_norm_var < -0.3\n    print(f\"   Result: {'SUPPORTED' if norm_var_supported else 'NOT SUPPORTED'}\")\n    \n    print(\"\\n2. ANGLE vs MEAN Conjecture:\")\n    print(f\"   Spearman correlation: {corr_angle_mean:.4f} (p={p_angle_mean:.4f})\")\n    print(f\"   Pearson correlation:  {pearson_angle_mean:.4f}\")\n    print(f\"   Expected: Strong correlation (similar means -> similar angles)\")\n    angle_mean_supported = abs(corr_angle_mean) > 0.3\n    print(f\"   Result: {'SUPPORTED' if angle_mean_supported else 'NOT SUPPORTED'}\")\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"STATE-BY-STATE ANALYSIS\")\n    print(\"=\"*70)\n    print(f\"{'State':<8} {'Norm':<10} {'Angle(deg)':<12} {'Mean T':<10} {'Var T':<10} {'Std T':<10}\")\n    print(\"-\"*70)\n    \n    for i, s in enumerate(states):\n        print(f\"{mdp.state_name(s):<8} {norms[i]:<10.4f} {np.degrees(angles[i]):<12.1f} \"\n              f\"{means[i]:<10.2f} {vars_[i]:<10.2f} {stds[i]:<10.2f}\")\n    \n    return {\n        'corr_norm_var': corr_norm_var,\n        'corr_angle_mean': corr_angle_mean,\n        'p_norm_var': p_norm_var,\n        'p_angle_mean': p_angle_mean,\n        'norms': norms,\n        'angles': angles,\n        'means': means,\n        'vars': vars_,\n        'states': states,\n        'norm_var_supported': norm_var_supported,\n        'angle_mean_supported': angle_mean_supported\n    }\n\n\nresults = test_conjecture(embeddings, hitting_stats, mdp)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def plot_summary(embeddings, results, hitting_stats, mdp):\n    \"\"\"\n    Create a comprehensive summary plot with Poincare disk, scatter plots, and statistics.\n    \"\"\"\n    fig = plt.figure(figsize=(16, 14))\n    \n    # Create grid spec for layout\n    gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.25)\n    \n    states = results['states']\n    norms = results['norms']\n    angles = results['angles']\n    means = results['means']\n    vars_ = results['vars']\n    coords = np.array([embeddings[s] for s in states])\n    \n    # =========================================================================\n    # Plot 1: Poincare Ball (top-left)\n    # =========================================================================\n    ax1 = fig.add_subplot(gs[0, 0])\n    \n    # Draw disk\n    circle = plt.Circle((0, 0), 1, color='black', fill=False, linewidth=2, linestyle='--')\n    ax1.add_patch(circle)\n    ax1.scatter([0], [0], s=60, c='black', marker='+', linewidth=2, zorder=10)\n    \n    # Color by variance (inverse - low var = brighter)\n    scatter = ax1.scatter(coords[:, 0], coords[:, 1], c=vars_, cmap='plasma_r',\n                         s=100, edgecolors='black', linewidth=1.5, zorder=5)\n    plt.colorbar(scatter, ax=ax1, label='Variance', shrink=0.8)\n    \n    for s in states:\n        emb = embeddings[s]\n        ax1.annotate(mdp.state_name(s), (emb[0], emb[1]), fontsize=11, fontweight='bold',\n                    xytext=(5, 5), textcoords='offset points')\n    \n    ax1.set_xlim(-1.15, 1.15)\n    ax1.set_ylim(-1.15, 1.15)\n    ax1.set_aspect('equal')\n    ax1.grid(True, alpha=0.2)\n    ax1.set_title('Poincaré Ball Embeddings\\n(colored by variance)', fontsize=13, fontweight='bold')\n    ax1.set_xlabel('x')\n    ax1.set_ylabel('y')\n    \n    # =========================================================================\n    # Plot 2: Norm vs Variance (top-right)\n    # =========================================================================\n    ax2 = fig.add_subplot(gs[0, 1])\n    \n    scatter = ax2.scatter(vars_, norms, c=means, cmap='viridis', s=100, \n                         edgecolors='black', linewidth=1.5)\n    plt.colorbar(scatter, ax=ax2, label='Mean Hitting Time', shrink=0.8)\n    \n    for i, s in enumerate(states):\n        ax2.annotate(mdp.state_name(s), (vars_[i], norms[i]), fontsize=11, fontweight='bold',\n                    xytext=(5, 5), textcoords='offset points')\n    \n    # Add trend line\n    z = np.polyfit(vars_, norms, 1)\n    p = np.poly1d(z)\n    x_trend = np.linspace(min(vars_) - 5, max(vars_) + 5, 100)\n    ax2.plot(x_trend, p(x_trend), 'r--', linewidth=2, alpha=0.7, label=f'Trend (slope={z[0]:.4f})')\n    \n    ax2.set_xlabel('Variance of Hitting Time', fontsize=11)\n    ax2.set_ylabel('Hyperbolic Norm', fontsize=11)\n    \n    # Add correlation annotation\n    corr = results['corr_norm_var']\n    status = \"SUPPORTED\" if corr < -0.3 else \"NOT SUPPORTED\"\n    color = 'green' if corr < -0.3 else 'red'\n    ax2.set_title(f'Conjecture 1: Norm vs Variance\\nρ = {corr:.3f} ({status})', \n                 fontsize=13, fontweight='bold', color='black')\n    ax2.legend(loc='upper right')\n    ax2.grid(True, alpha=0.3)\n    \n    # =========================================================================\n    # Plot 3: Angle vs Mean (bottom-left)\n    # =========================================================================\n    ax3 = fig.add_subplot(gs[1, 0])\n    \n    scatter = ax3.scatter(means, np.degrees(angles), c=vars_, cmap='plasma', s=100,\n                         edgecolors='black', linewidth=1.5)\n    plt.colorbar(scatter, ax=ax3, label='Variance', shrink=0.8)\n    \n    for i, s in enumerate(states):\n        ax3.annotate(mdp.state_name(s), (means[i], np.degrees(angles[i])), fontsize=11, fontweight='bold',\n                    xytext=(5, 5), textcoords='offset points')\n    \n    # Add trend line\n    z = np.polyfit(means, np.degrees(angles), 1)\n    p = np.poly1d(z)\n    x_trend = np.linspace(min(means) - 1, max(means) + 1, 100)\n    ax3.plot(x_trend, p(x_trend), 'r--', linewidth=2, alpha=0.7, label=f'Trend (slope={z[0]:.2f})')\n    \n    ax3.set_xlabel('Mean Hitting Time', fontsize=11)\n    ax3.set_ylabel('Angular Coordinate (degrees)', fontsize=11)\n    \n    corr = results['corr_angle_mean']\n    status = \"SUPPORTED\" if abs(corr) > 0.3 else \"NOT SUPPORTED\"\n    ax3.set_title(f'Conjecture 2: Angle vs Mean\\nρ = {corr:.3f} ({status})', \n                 fontsize=13, fontweight='bold')\n    ax3.legend(loc='best')\n    ax3.grid(True, alpha=0.3)\n    \n    # =========================================================================\n    # Plot 4: Summary Statistics (bottom-right)\n    # =========================================================================\n    ax4 = fig.add_subplot(gs[1, 1])\n    ax4.axis('off')\n    \n    # Create summary text\n    norm_var_status = \"SUPPORTED\" if results['norm_var_supported'] else \"NOT SUPPORTED\"\n    angle_mean_status = \"SUPPORTED\" if results['angle_mean_supported'] else \"NOT SUPPORTED\"\n    \n    summary_text = f\"\"\"\n╔══════════════════════════════════════════════════════════╗\n║              HYPOTHESIS TEST SUMMARY                      ║\n╠══════════════════════════════════════════════════════════╣\n║                                                          ║\n║  CONJECTURE 1: Norm ∝ 1/Variance                         ║\n║  ─────────────────────────────────────────────────────   ║\n║  Expected: Low variance → High norm (negative corr)      ║\n║  Spearman ρ = {results['corr_norm_var']:+.4f}  (p = {results['p_norm_var']:.4f})                  ║\n║  Status: {norm_var_status:<20}                       ║\n║                                                          ║\n╠══════════════════════════════════════════════════════════╣\n║                                                          ║\n║  CONJECTURE 2: Angle ∝ Mean                              ║\n║  ─────────────────────────────────────────────────────   ║\n║  Expected: Similar mean → Similar angle (strong corr)    ║\n║  Spearman ρ = {results['corr_angle_mean']:+.4f}  (p = {results['p_angle_mean']:.4f})                  ║\n║  Status: {angle_mean_status:<20}                       ║\n║                                                          ║\n╠══════════════════════════════════════════════════════════╣\n║                                                          ║\n║  STATE STATISTICS:                                       ║\n║  ─────────────────────────────────────────────────────   ║\"\"\"\n    \n    for i, s in enumerate(states):\n        summary_text += f\"\\n║  {mdp.state_name(s)}: norm={norms[i]:.2f}, angle={np.degrees(angles[i]):+6.1f}°, \"\n        summary_text += f\"μ={means[i]:5.1f}, σ²={vars_[i]:6.1f}  ║\"\n    \n    summary_text += \"\"\"\n║                                                          ║\n╚══════════════════════════════════════════════════════════╝\n\"\"\"\n    \n    ax4.text(0.02, 0.98, summary_text, transform=ax4.transAxes, fontsize=10,\n            verticalalignment='top', fontfamily='monospace',\n            bbox=dict(boxstyle='round,pad=0.5', facecolor='lightyellow', alpha=0.9, edgecolor='black'))\n    \n    plt.suptitle('MDP Hyperbolic Embedding Analysis', fontsize=16, fontweight='bold', y=0.98)\n    plt.tight_layout()\n    plt.savefig('mdp_summary.png', dpi=150, bbox_inches='tight', facecolor='white')\n    plt.show()\n\n\nplot_summary(embeddings, results, hitting_stats, mdp)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conjecture_analysis(results, mdp):\n",
    "    \"\"\"\n",
    "    Detailed visualization of the conjecture analysis.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    \n",
    "    norms = results['norms']\n",
    "    angles = results['angles']\n",
    "    means = results['means']\n",
    "    vars_ = results['vars']\n",
    "    states = results['states']\n",
    "    \n",
    "    # Plot 1: Norm vs Variance\n",
    "    ax = axes[0, 0]\n",
    "    scatter = ax.scatter(vars_, norms, c=means, cmap='viridis', s=200, edgecolors='black', linewidth=2)\n",
    "    plt.colorbar(scatter, ax=ax, label='Mean Hitting Time')\n",
    "    \n",
    "    for i, s in enumerate(states):\n",
    "        ax.annotate(mdp.state_name(s), (vars_[i], norms[i]), fontsize=12, fontweight='bold',\n",
    "                   xytext=(5, 5), textcoords='offset points')\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(vars_, norms, 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_trend = np.linspace(min(vars_), max(vars_), 100)\n",
    "    ax.plot(x_trend, p(x_trend), 'r--', linewidth=2, label=f'Trend (slope={z[0]:.4f})')\n",
    "    \n",
    "    ax.set_xlabel('Variance of Hitting Time', fontsize=12)\n",
    "    ax.set_ylabel('Hyperbolic Norm', fontsize=12)\n",
    "    ax.set_title(f'Conjecture 1: Norm vs Variance\\nCorr={results[\"corr_norm_var\"]:.3f}', fontsize=14)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Angle vs Mean\n",
    "    ax = axes[0, 1]\n",
    "    scatter = ax.scatter(means, np.degrees(angles), c=vars_, cmap='plasma', s=200, edgecolors='black', linewidth=2)\n",
    "    plt.colorbar(scatter, ax=ax, label='Variance')\n",
    "    \n",
    "    for i, s in enumerate(states):\n",
    "        ax.annotate(mdp.state_name(s), (means[i], np.degrees(angles[i])), fontsize=12, fontweight='bold',\n",
    "                   xytext=(5, 5), textcoords='offset points')\n",
    "    \n",
    "    ax.set_xlabel('Mean Hitting Time', fontsize=12)\n",
    "    ax.set_ylabel('Angular Coordinate (degrees)', fontsize=12)\n",
    "    ax.set_title(f'Conjecture 2: Angle vs Mean\\nCorr={results[\"corr_angle_mean\"]:.3f}', fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Norm vs Mean\n",
    "    ax = axes[1, 0]\n",
    "    scatter = ax.scatter(means, norms, c=vars_, cmap='plasma', s=200, edgecolors='black', linewidth=2)\n",
    "    plt.colorbar(scatter, ax=ax, label='Variance')\n",
    "    \n",
    "    for i, s in enumerate(states):\n",
    "        ax.annotate(mdp.state_name(s), (means[i], norms[i]), fontsize=12, fontweight='bold',\n",
    "                   xytext=(5, 5), textcoords='offset points')\n",
    "    \n",
    "    corr_norm_mean = np.corrcoef(norms, means)[0, 1]\n",
    "    ax.set_xlabel('Mean Hitting Time', fontsize=12)\n",
    "    ax.set_ylabel('Hyperbolic Norm', fontsize=12)\n",
    "    ax.set_title(f'Additional: Norm vs Mean\\nCorr={corr_norm_mean:.3f}', fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Summary stats\n",
    "    ax = axes[1, 1]\n",
    "    ax.axis('off')\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "    CONJECTURE ANALYSIS SUMMARY\n",
    "    {'='*50}\n",
    "    \n",
    "    Conjecture 1: Norm ~ Variance\n",
    "    -----------------------------\n",
    "    Spearman correlation: {results['corr_norm_var']:.4f}\n",
    "    Interpretation: {'SUPPORTED' if results['corr_norm_var'] > 0.3 else 'WEAK/NOT SUPPORTED'}\n",
    "    \n",
    "    Conjecture 2: Angle ~ Mean\n",
    "    ---------------------------\n",
    "    Spearman correlation: {results['corr_angle_mean']:.4f}\n",
    "    Interpretation: {'SUPPORTED' if abs(results['corr_angle_mean']) > 0.3 else 'WEAK/NOT SUPPORTED'}\n",
    "    \n",
    "    {'='*50}\n",
    "    \n",
    "    Note: The MDP has structure that affects embeddings:\n",
    "    - S4, S5: 1-step to goal (low var, low mean)\n",
    "    - S2, S3: Geometric waiting (high var, high mean)\n",
    "    - S1: Depends on action choice\n",
    "    \"\"\"\n",
    "    \n",
    "    ax.text(0.05, 0.95, summary_text, transform=ax.transAxes, fontsize=11,\n",
    "            verticalalignment='top', fontfamily='monospace',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('conjecture_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_conjecture_analysis(results, mdp)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def plot_all_state_pairs(model, mdp):\n    \"\"\"\n    Plot embeddings for ALL (state, goal) pairs, not just (state, final_goal).\n    \"\"\"\n    model.eval()\n    n_states = mdp.n_states\n    \n    fig, ax = plt.subplots(figsize=(10, 10))\n    plot_poincare_disk(ax, \"All (State, Goal) Pair Embeddings\")\n    \n    all_embeddings = []\n    labels = []\n    colors = []\n    \n    with torch.no_grad():\n        for start in range(n_states):\n            for goal in range(n_states):\n                if start != goal:  # Skip self-loops\n                    s_norm = start / (n_states - 1)\n                    g_norm = goal / (n_states - 1)\n                    \n                    x = torch.tensor([[s_norm, g_norm]], dtype=torch.float32).to(device)\n                    emb = model(x)\n                    \n                    if isinstance(emb, ManifoldTensor):\n                        emb = emb.tensor\n                    \n                    emb = emb.squeeze(0).cpu().numpy()\n                    all_embeddings.append(emb)\n                    labels.append(f\"({mdp.state_name(start)},{mdp.state_name(goal)})\")\n                    colors.append(goal)  # Color by goal state\n    \n    all_embeddings = np.array(all_embeddings)\n    colors = np.array(colors)\n    \n    scatter = ax.scatter(all_embeddings[:, 0], all_embeddings[:, 1], \n                        c=colors, cmap='tab10', s=80, edgecolors='black', linewidth=1, zorder=5)\n    \n    # Add labels\n    for i, label in enumerate(labels):\n        ax.annotate(label, all_embeddings[i], fontsize=7, \n                   xytext=(3, 3), textcoords='offset points')\n    \n    plt.colorbar(scatter, ax=ax, label='Goal State Index')\n    plt.tight_layout()\n    plt.savefig('all_state_pairs.png', dpi=150, bbox_inches='tight')\n    plt.show()\n\n\nplot_all_state_pairs(model, mdp)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def plot_polar_representation(embeddings, hitting_stats, mdp):\n    \"\"\"\n    Polar plot showing angle vs hyperbolic norm.\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={'projection': 'polar'})\n    \n    states = sorted(embeddings.keys())\n    \n    angles = [np.arctan2(embeddings[s][1], embeddings[s][0]) for s in states]\n    norms = [hyperbolic_norm(embeddings[s]) for s in states]\n    means = [hitting_stats[s]['mean'] for s in states]\n    vars_ = [hitting_stats[s]['var'] for s in states]\n    \n    # Size by inverse variance (low variance = larger), color by mean\n    max_var = max(vars_) if max(vars_) > 0 else 1\n    sizes = 50 + 100 * (1 - np.array(vars_) / max_var)\n    \n    scatter = ax.scatter(angles, norms, c=means, cmap='viridis', s=sizes, \n                        edgecolors='black', linewidth=1.5)\n    plt.colorbar(scatter, ax=ax, label='Mean Hitting Time', pad=0.1)\n    \n    for i, s in enumerate(states):\n        ax.annotate(mdp.state_name(s), (angles[i], norms[i]), fontsize=11, fontweight='bold')\n    \n    ax.set_title('Polar View: Angle vs Hyperbolic Norm\\n(Size ~ 1/Variance, Color ~ Mean)', fontsize=13, pad=20)\n    \n    plt.tight_layout()\n    plt.savefig('polar_embeddings.png', dpi=150, bbox_inches='tight')\n    plt.show()\n\n\nplot_polar_representation(embeddings, hitting_stats, mdp)"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Discussion\n\n### MDP Structure Analysis\n\nThe MDP has distinct structural properties that affect hitting times:\n\n1. **States 4 and 5 (S4, S5)**: Deterministic 1-step transitions to goal\n   - Mean hitting time: 1\n   - Variance: 0\n   \n2. **States 2 and 3 (S2, S3)**: Geometric waiting times due to self-loops\n   - Mean hitting time: ~10-11 (expected value of geometric(0.1) + 1)\n   - Variance: ~90 (variance of geometric distribution)\n   \n3. **State 1 (S1)**: Depends on action selection\n   - Under random policy: mix of 2-step (via a11) and longer paths (via a12, a13)\n\n### Conjecture Interpretation\n\nThe conjecture states:\n- **Norm ~ 1/Variance**: States with **lower** hitting time variance should be embedded **farther** from the origin (higher norm)\n- **Angle ~ Mean**: States with similar mean hitting times should have similar angular coordinates\n\nThis would create a structure where:\n- S4, S5 (low variance, deterministic) should have **high norms** (far from origin)\n- S2, S3 (high variance, geometric waiting) should have **low norms** (near origin)\n- States with similar means lie along similar radial directions\n\n### Intuition\n\nIn hyperbolic space, the origin represents maximal uncertainty/abstraction. States with:\n- **Low variance** (predictable hitting times) are more \"specific\" → farther from origin\n- **High variance** (unpredictable hitting times) are more \"abstract\" → closer to origin"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Final summary\nprint(\"=\"*70)\nprint(\"FINAL SUMMARY\")\nprint(\"=\"*70)\nprint(f\"\\nTraining completed with {len(trajectories)} trajectories\")\nprint(f\"Final training loss: {losses[-1]:.4f}\")\n\nprint(f\"\\n--- Conjecture 1: Norm ~ 1/Variance ---\")\nprint(f\"Spearman correlation: {results['corr_norm_var']:.4f}\")\nprint(f\"Expected: Negative (low variance -> high norm)\")\nprint(f\"Status: {'SUPPORTED' if results['norm_var_supported'] else 'NOT SUPPORTED'}\")\n\nprint(f\"\\n--- Conjecture 2: Angle ~ Mean ---\")\nprint(f\"Spearman correlation: {results['corr_angle_mean']:.4f}\")\nprint(f\"Expected: Strong correlation\")\nprint(f\"Status: {'SUPPORTED' if results['angle_mean_supported'] else 'NOT SUPPORTED'}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"See the summary plot above for detailed visualization.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTraining completed with {len(trajectories)} trajectories\")\n",
    "print(f\"Final training loss: {losses[-1]:.4f}\")\n",
    "print(f\"\\nConjecture 1 (Norm ~ Variance): correlation = {results['corr_norm_var']:.4f}\")\n",
    "print(f\"Conjecture 2 (Angle ~ Mean): correlation = {results['corr_angle_mean']:.4f}\")\n",
    "print(\"\\nSee visualizations above for detailed analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}